# -*- coding: utf-8 -*-
"""Healtech_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-5qDXBLjEeFKpdm4BHL8hGSvw1gVesqJ

# Helteck Project
---
**Fecha de Desarrollo:**

- 22-Feb-2024

**Notebook**

- Julio C茅sar Mart铆nez

**Tipo de Proyecto:**

- Data Science

## Introducci贸n

En la era actual de la medicina, el poder de la tecnolog铆a est谩 transformando radicalmente la forma en que diagnosticamos y tratamos enfermedades. Entre las innovaciones m谩s prometedoras, el aprendizaje autom谩tico, especialmente la clasificaci贸n, ha surgido como una herramienta invaluable para mejorar la precisi贸n y la eficiencia en el diagn贸stico m茅dico.

Este proyecto se centra en la aplicaci贸n de t茅cnicas de aprendizaje autom谩tico en el campo de la medicina, espec铆ficamente en la clasificaci贸n de enfermedades con el objetivo de proporcionar diagn贸sticos m谩s r谩pidos y precisos, lo que a su vez puede mejorar los resultados del paciente y optimizar el uso de recursos m茅dicos. Con un enfoque en la clasificaci贸n, este proyecto busca explorar c贸mo los algoritmos de aprendizaje autom谩tico pueden analizar datos cl铆nicos, im谩genes m茅dicas y otros biomarcadores para identificar patrones que ayuden a distinguir entre diferentes condiciones m茅dicas con alta precisi贸n y confiabilidad.

A trav茅s de esta investigaci贸n, se espera avanzar en la capacidad de los profesionales de la salud para diagnosticar y tratar enfermedades de manera m谩s efectiva, mejorando as铆 la calidad de vida de los pacientes y contribuyendo al avance general de la medicina.

## Tabla de Contenido

1. Descargar los datos
2. An谩lisis de cada Variable
3. An谩lisis de Relaci贸n entre Variables

## Objetivos

Proyecto de clasificaci贸n, para diagnosticar medicamenttos bas谩ndose en las caracteristicas de los pacientes.

## <span style="color:green">1. Descargar los datos </span>

EN ESTE PROYECTO SOLO VAMOS A NECESITAR LA BASE DE DATOS drug300.csv.

https://github.com/a2Proyectos/MachineLearning_Data
"""

# Importa las librerias <3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict
from sklearn.linear_model import SGDClassifier
from sklearn.base import BaseEstimator
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier

## Define una funci贸n para extraer los datos
#DOWNLOAD_ROOT es la base del GitHub donde vamos a estar descargando las bases de datos.
DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/a2Proyectos/MachineLearning_Data/main/'
#Complementos con la direcci贸n especifica de la base de datos que queremos.
MEDICAMENTOS  = 'Capitulo_3/drug200.csv'

# Visualiza el DataFrame
df = pd.read_csv(DOWNLOAD_ROOT + MEDICAMENTOS)

# Obten informaci贸n de los datos.
df.info()

"""## <span style="color:green">2. An谩lisis de cada Variable</span>"""

# Distribuci贸n de Edad
plt.figure(figsize=(9,5))
sns.displot(df['Age'], kde=True)
plt.title('Distribuci贸n por Edad');

# Distribuci贸n de G茅nero
print('Cantidad de hombres y mujeres que hay')
print()
df['Sex'].value_counts()

# An谩lisis de Presi贸n Sanguinea
plt.figure(figsize=(9,5))
sns.histplot(data=df,x='BP',hue='BP')
plt.title('Distribuci贸n de Presi贸n sanguinea');

# Crea una gr谩fica de barras para Colesterol
plt.figure(figsize=(9,5))
sns.histplot(data=df,x='Cholesterol',hue='Cholesterol')
plt.title('An谩lisis de Colesterol');

df['Cholesterol'].value_counts()

# Revisando sodio-potacio
plt.figure(figsize=(9,5))
sns.displot(df['Na_to_K'],kde=True)
plt.title('An谩lisis Sodio-Potacio');

# Crea una gr谩fica de barras para los Medicamentos (droga) 
plt.figure(figsize=(9,5))
sns.histplot(data=df, x=df['Drug'],hue='Drug')
plt.title('Distribuci贸n Medicamentos');

df['Drug'].value_counts()

"""***

## <span style="color:green">3. An谩lisis de Relaci贸n entre Variables</span>
"""

## La relaci贸n entre la Edad y los Medicamentos que se les da acorde a 
plt.figure(figsize=(9,5))
sns.swarmplot(x='Drug',y='Age',data=df,hue='Drug')
plt.legend(df['Drug'].value_counts().index)
plt.title('Edad vs Medicamentos');

# La relaci贸n entre el el G茅nero y los Medicamentos  que se les da
# Armar una tabla para poder graficarlas
df_sex_drugs = df.groupby(['Sex','Drug']).size().reset_index(name='Count')
df_sex_drugs

plt.figure(figsize=(9,5))
sns.barplot(x='Drug',y='Count',data=df_sex_drugs,hue='Sex');

# Grafica la relaci贸n entre la Presi贸n Sangu铆nea y los Medicamentos 
df_BP_Drug = df.groupby(['BP','Drug']).size().reset_index(name='Count')
df_BP_Drug

plt.figure(figsize=(9,5))
sns.barplot(x='Drug',y='Count',hue='BP',data=df_BP_Drug)
plt.title('Presion vs Medicamentos');

# Grafica (con una gr谩fica de barras) la relaci贸n entre el nivel de colesterol y los medicamentos 
df_CH_Drug = df.groupby(['Drug','Cholesterol']).size().reset_index(name='Count')
df_CH_Drug

plt.figure(figsize=(9,5))
sns.barplot(x='Drug',y='Count',hue='Cholesterol',data=df_CH_Drug)
plt.title('Medicamentos vs Colesterol');

#Grafica (con un swarmplot) la relaci贸n entre el nivel de Sodio-Potasio y los medicamentos  que se les da
plt.figure(figsize=(9,5))
sns.swarmplot(x='Drug',y='Na_to_K',data=df,hue='Drug')
plt.legend(df['Drug'].value_counts().index)
plt.title('Medicamentos vs Sodio/Potacio');

"""***

## <span style="color:green">4. Limpieza y Separaci贸n de Datos</span>
"""

## Utilizar LabelEncoder para procesar variables alfanum茅ricas como el sexo, BP, Colesterol, 茅tc

def label_encoder(datos_categoria):
  le = LabelEncoder()
  df[datos_categoria]=le.fit_transform(df[datos_categoria])

variables = ['Sex','BP','Cholesterol','Na_to_K','Drug']

for L in variables:
  label_encoder(L)

df.head()

# Crear set de entrenamiento y set de prueba
x = df.drop('Drug',axis=1)
y = df['Drug']

"""El 20% de los datos, ser谩n de prueba. Shuffle ser谩 true. Semilla de Aleatoriedad=42"""

x_train,x_test,y_train,y_test = train_test_split(
    x,
    y,
    test_size=0.2,
    random_state=42,
    shuffle=True
    )

"""***

## <span style="color:green">5. Modelo de Clasificaci贸n Binario</span>
"""

## Crear modelo para medicamento
y_train_y = (y_train == 0)
y_test_y = (y_test == 0)

"""Empezaremos con la medicina Y porque es la m谩s popular y, por ende la m谩s f谩cil de predecir"""

## Modelo SGD = Stochastic Gradient Descent
sgd = SGDClassifier()
sgd.fit(x_train,y_train_y)

df.head(1)

#Predecir la medicina a tomar de un humano que ya sepas el resultado
sgd.predict([x_train.loc[0]]),y_train_y.loc[0]

""": para saber que le esta yendo bien al modelo tienen que coincidir los resultados

***

## <span style="color:green">6. Medidas de desempe帽o</span>

### <span style="color:blue">6.1 Exactitud</span>
"""

# Realiza una Cross validation/K-Folds
cross_val_score(
    sgd,
    x_train,
    y_train_y,
    cv=3,
    scoring="accuracy")

"""
**cv:** n煤mero de dobleses

**scoring:** accuracy (ser谩 nuestra medida de desempe帽o)"""

# Modelo que nunca es Y
class NuncaC(BaseEstimator):
  def fit(self,X,y=None):
    return self
  def predict(self,X):
    return np.zeros((len(X),1),dtype=bool)

nunca_y = NuncaC()
cross_val_score(
    nunca_y,
    x_train,
    y_train_y,
    cv=3,
    scoring="accuracy")

"""***

### <span style="color:blue">6.2 Matriz de Confusi贸n</span>
"""

# Matriz de confusi贸n
y_train_pred = cross_val_predict(
    sgd,x_train,y_train_y,cv=3)
confusion_matrix(
    y_train_y,y_train_pred)

"""![matriz.png](attachment:3f90b91e-ff94-40c8-b015-0fd5b2eb1586.png)

**Verdaderos Negativos**: esquina superior izquierda

**Falsos positivos**: esquina superior derecha

**Falsos Negativos**: esquina inferior izquierda

**Verdaderos Positivos**: esquina inferior derecha

***

### <span style="color:blue">6.3 Precision y Recall</span>
"""

p = precision_score(y_train_y, y_train_pred)
r = recall_score(y_train_y, y_train_pred)
p,r

"""$Precision = vp/vp + fp$

$Recall = vp / vp + fn$
"""

#Cambiar de clasificador a RandomForest
rfc = RandomForestClassifier(random_state=42)
rfc.fit(x_train,y_train_y)
#Hacer cross validation score
y_train_pred = cross_val_predict(rfc,x_train,y_train_y,cv=3)

# Matriz de confusi贸n
confusion_matrix(y_train_y,y_train_pred)

#Calcular presicion and recall
p = precision_score(y_train_y,y_train_pred)
r = recall_score(y_train_y,y_train_pred)
p,r

# F1
f1_score(y_train_y,y_train_pred)

"""***

### <span style="color:blue">6.4 Umbral Precision y Recall</span>
"""

#Puntaci贸n de un paciente aleatorio
df.head(1)

y_score = sgd.decision_function([x_train.loc[0]])
y_score

#Graficar la precisi贸n y recall
y_scores = cross_val_predict(sgd,x_train,y_train_y,method='decision_function')
precisions,recalls,umbrales = precision_recall_curve(y_train_y, y_scores)
#Puedes visualizar los y_scores pero no te dice nada, la gr谩fica si lo har谩
#Graficar la precisi贸n y recall, ahora si
plt.plot(umbrales,precisions[:-1],'b--',label='Precision')
plt.plot(umbrales,recalls[:-1],'g-',label='Recall')
plt.show();

"""El umbral te permite conocer qu茅 medida priorizar acorde a tus objetivos. Ya sea que estemos hablando de videos de youtube para ni帽os  o un sistema de seguridad ."""

#Supon que ya lo pensaste y quer铆as un umbral  90
umbral_90 = umbrales[np.argmax(precisions >= 0.9)]
umbral_90

#Arroja la precisi贸n y recall para un umbral de 90
y_train_90 = (y_scores >= umbral_90)

p = precision_score(y_train_y,y_train_90)
r = recall_score(y_train_y,y_train_90)
p,r

"""***

### <span style="color:blue">6.5 Curva ROC</span>

Grafica Recall contra el porcentaje de Falsos Positivos
"""

#Importar roc_curve
fpr, tpr, umbrales = roc_curve(y_train_y, y_scores)

#Graficar la curva ROC
plt.plot(fpr,tpr,label='ROC Curve')
plt.plot([0,1],[0,1],'k--')
plt.xlabel('FPR - False Positive Rate')
plt.ylabel('TPR - RECALL')
plt.grid()
plt.show();

"""Un modelo perfecto se asimila a una escuadra entre la curva ROC y la l铆nea punteada porque existe una mayor 谩rea bajo la curva"""

#Calcular el puntaje de la curva
roc_auc_score(y_train_y,y_scores)

#Compararlo con el modelo de random forest
y_forest = cross_val_predict(rfc,x_train,y_train_y,cv=3,method='predict_proba')
y_scores_forest = y_forest[:,1]
fpr_forest,tpr_forest,umbral_forest = roc_curve(y_train_y,y_scores_forest)

#Graficar la curva ROC y la predicci贸n de random forest
plt.plot(fpr,tpr,label='ROC Curve')
plt.plot(fpr_forest,tpr_forest, label='RF ROC CURVE')
plt.plot([0,1],[0,1],'k--')
plt.xlabel('FPR - False Positive Rate')
plt.ylabel('TPR - RECALL')
plt.grid()
plt.show();

#Calcular el puntaje (谩rea bajo la curva) de random forest
roc_auc_score(y_train_y,y_scores_forest)

"""***

## <span style="color:green">7. Clasificadores Multiclase</span>
"""

# Importar SVC=Support Vector Classifier
# Predecir a un humano aleatorio para ver que todo este funcionando bien
svm = SVC()
svm.fit(x_train, y_train)

# Revisar al paciente cero
df.head(3)

# Predecir al paciente cero
prediccion_cero = svm.predict([x_train.loc[0]])
print('prediccion paciente cero:', prediccion_cero)

#Utilizar decision_function para observar los puntajes de cada medicina
#Decidir谩 por el qu茅 tenga mayor puntaje
probabilidad_decision = svm.decision_function([x_train.loc[0]])
print('probabilidad de decisi贸n entre los 5 medicamentos:\n', probabilidad_decision)

"""En la modalidad 1vs1 svm clasifica como correcto la medicina cero gracias a su alto puntaje con 4.29 aunque la medicina 4 tambi茅n se acerc贸 mucho, eso es algo que llama la atenci贸n."""

#Ahora, utiliza el clasificador multiclase
#Predecir a un humano ahora con este clasificador
svm = OneVsRestClassifier(SVC())
svm.fit(x_train, y_train)

print('predicci贸n paciente cero')
svm.predict([x_train.loc[0]])

#Utilizar decision_function para observar los puntajes de cada medicina
print('puntajes de decisi贸n para el paciente cero:')
svm.decision_function([x_train.loc[0]])

"""Se puede ver como en la modalidad 1 vs rest, el modelo clasifica el resto de medicinas con valores negativos, mientras que la medicina cero la clasifica con 2.3. Esto significa que este modelo es m谩s seguro a la hora de predecir en comparaci贸n con el modelo anterior."""

#campararlo con los datos obtenidos de sgd.fit
sgd.fit(x_train,y_train)

print('prediccion paciente cero con sgd')
sgd.predict([x_train.loc[0]])

print('funci贸n de decisi贸n paciente cero')
sgd.decision_function([x_train.loc[0]])

"""***

## <span style="color:green">8. Analizar Errores</span>
"""

#Hacer un clasificador de random forest
rfc.fit(x_train,y_train)

print('predicci贸n paciente cero con rfc')
rfc.predict([x_train.loc[0]])

#Utilizar la matriz de confusi贸n
y_pred  = cross_val_predict(rfc,x_train,y_train,cv=3)
conf_mx = confusion_matrix(y_train, y_pred)

print('matriz de confusi贸n')
conf_mx

#utilizar ahora SGD
y_train_pred  = cross_val_predict(sgd,x_train,y_train,cv=3)
conf_mx = confusion_matrix(y_train, y_pred)

print('matriz de confusi贸n para sgd train')
conf_mx

y_test_pred = sgd.predict(x_test)
conf_mx_test = confusion_matrix(y_test,y_test_pred)

print('matriz de confusion para sgd test')
conf_mx_test



"""---

## 9 Conclusiones

- El objetivo de este proyecto fue desarrollar un modelo de clasificaci贸n que nos ayudara a escoger medicamentos para los pacientes de acuerdo a caracter铆sticas como la edad, g茅nero, niveles de colesterol, sodio, potacio, etc.

- Dentro de nuestra investigaci贸n, descubrimos que el mejor modelo de machine learning para clasificar a cada paciente, es el modelo **Random Forest**, el cual clasifico perfectamente a cada paciente dentro del set de pruebas, esta informaci贸n se corrobora gracias al an谩lsis de errores que se muestra en **la matriz de confusi贸n**.

- Esperemos que con este resultado, este modelo pueda servir para ayudar a m谩s m茅dicos, consultorios y hospitales en pro de sus pacientes medic谩ndolos de la manera correcta.
"""